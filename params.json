{
  "name": "Humour-detection",
  "tagline": "Humour detection in Yelp reviews",
  "body": "# Humour-Detection\r\nHumour detection in Yelp reviews\r\n\r\n####Problem Statement : \r\nTo utilize the state-of-the-art in deep learning methods and show that deep learning can capture the higher order structure of humor in Yelp reviews, by comparing with state-of-the-art shallow learning techniques. \r\n\r\n###Applications :\r\nHumor is a necessary part of all verbal communication. With the advancement of computational technologies, increasingly more emphasis is being placed on systems that can handle human natural language effectively. Thus, without humor detection and generation, no natural language system can be considered successful. It is necessary for a full computational understanding of natural language documents and for enabling intelligent conversational agents to handle humor.\r\n\r\nDomain specific application: Yelp is a platform which aims to provide accurate, crowd-sourced opinion about a place of business. Humour detection in the reviews present there, can be used to determine the importance, or the genuineness of a particular review.\r\n\r\n###Challenges\r\n- Any results derived from work on Yelp data may end up being highly domain specific. But, the lack of any openly available dataset for humour leaves no option.\r\n- The human classification of something as “humour” can be very subjective.\r\n\r\n###Dataset:\r\nWe are using the  Yelp Dataset Challenge dataset, which consists of about 1.6 million reviews by 366,000 users for 61,000 businesses. Each yelp review has user given votes for three categories - “funny”, “cool” and “useful”.  We are using this community provided data to get our dataset. Any review with more than 3 “funny votes” is taken as funny, and the others as not-funny. We extracted a balanced set of 1,00,000 reviews, containing equal number of samples for both classes. This data is be used for training and testing purposes for this project.\r\n\r\n\r\n###Modules:\r\n1. SVM on bag-of-words word representations, 5-fold cross validation\r\n  * Linear kernel\r\n  * RBF Kernel\r\n2. Feed Forward Network on word2vec generated word vectors\r\n3. Convulational Neural Networks\r\n\r\n###Run:\r\n\r\n   Before running make sure all requirements are installed \r\n\r\n     > pip install -r requirements.txt\r\n\r\n\r\n1. For SVM built on top of bag-of-words word representations \r\n\t   \r\n       > python svm_bagOfWords.py\r\n\r\n   Then on prompt enter either \"linear\" or \"rbf\" as per your choice\r\n   \r\n2. Feed Forward Neural Networks (FFN) built on top of word2vec genrated word vectors:\r\n\r\n   \tGive the output file name of preprocess.py program as input argument to Word2Vec.py in RUN_FFN.sh\r\n\t> bash RUN_FFN.sh\r\n\r\n3. Convulational neural networks:\r\n\r\n    The code given in Yoon Kim's code for [CNN for sentence classification](https://github.com/yoonkim/CNN_sentence) was used. After being trained on googles word2vec dataset, our dataset was used for testing purposes.\r\n\r\n###Results:\r\nAccuracy scores achieved were as follows:\r\n\r\n1. SVM\r\n  - Linear Kernel: 0.83\r\n  - RBF kernel: 0.497\r\n\r\n2. Feed Forward Neural Network:  0.75\r\n\r\n2. Convolutional Neural Network\r\n  - Static: \r\n    - word2vec: 0.83\r\n    - random: 0.75\r\n  - Non-static:\r\n    - word2vec: 0.83\r\n    - random: 0.78\r\n\r\n###References:\r\n- [Oliveira and Rodrigo, \"Humor Detection in Yelp reviews\" ](https://cs224d.stanford.edu/reports/OliveiraLuke.pdf)\r\n- [Yoon Kim, \"Convolutional Neural Networks for Sentence Classification\"](http://emnlp2014.org/papers/pdf/EMNLP2014181.pdf)\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}